{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571ba487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "DATA_DIR = Path(parent_dir) / \"data\"\n",
    "IMAGES_DIR = DATA_DIR / \"images\"\n",
    "INDEX_DIR = DATA_DIR / \"index\"\n",
    "INDEX_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626acb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b00d241474c56a3e7f1817f25234f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b979f367902349b8b0be4731bede5ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8cf336e8cf4e8b990f70cd0fdb194d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09f72e8ff6b49c0b0e830c5c5a4990a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b377e34bf3ec4ac4b4941e434a8811cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a648e8807ab4991b48311ba9d2e5671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee0350d93064606815bece76028d26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b628bea328a4242b87b81666d09168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29efbe480eb140499ce0060933c14613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CLIP model: openai/clip-vit-base-patch32\n"
     ]
    }
   ],
   "source": [
    "# Load CLIP model for image embeddings\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded CLIP model: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a52ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4095 products from dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>protein</th><th>fat</th><th>title</th><th>is_edible</th><th>carbohydrates</th><th>category</th><th>calories</th><th>public_url</th><th>id</th><th>_id</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>bool</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>0.0</td><td>0.0</td><td>&quot;–ó–µ–ª—ë–Ω—ã–π —á–∞–π_Bayce 95-11 400–≥—Ä&quot;</td><td>true</td><td>0.0</td><td>&quot;Beverage&quot;</td><td>2.0</td><td>&quot;https://safebite-s3.s3.amazona‚Ä¶</td><td>69972</td><td>&quot;01Uz9Eh4tMKkkUI8zmTr&quot;</td></tr><tr><td>1.0</td><td>2.5</td><td>&quot;–ú–æ—Ä–æ–∂. –ë–æ–Ω –ü–∞—Ä–∏ —Å —Ñ—Ä—É–∫—Ç.—Å–æ–∫–æ–º&quot;</td><td>true</td><td>25.0</td><td>&quot;Ice Cream&quot;</td><td>125.0</td><td>&quot;https://safebite-s3.s3.amazona‚Ä¶</td><td>69332</td><td>&quot;01YaRoAioWVJaPOTy85E&quot;</td></tr><tr><td>-1.0</td><td>-1.0</td><td>&quot;–®–æ–∫ –ø–ª–∏—Ç –†–æ—Å—Å–∏—è —Ç–µ–º –º–∏–Ω–¥–∞–ª—å 82‚Ä¶</td><td>true</td><td>-1.0</td><td>&quot;Chocolate&quot;</td><td>-1.0</td><td>&quot;https://safebite-s3.s3.amazona‚Ä¶</td><td>9041</td><td>&quot;02UfvwkJzBRyUHDFdq2v&quot;</td></tr><tr><td>27.5</td><td>25.0</td><td>&quot;Delmark_–°/–ö_–û—Ö–æ—Ç–Ω–∏—á—å—è&quot;</td><td>true</td><td>2.5</td><td>&quot;Meat Product&quot;</td><td>350.0</td><td>&quot;https://safebite-s3.s3.amazona‚Ä¶</td><td>43181</td><td>&quot;035LM4tsGLrKLY9QpQ2m&quot;</td></tr><tr><td>0.0</td><td>0.0</td><td>&quot;–ì–†–ò–ù–§–ò–õ–î –ì–æ–ª–¥–µ–Ω –¶–µ–π–ª–æ–Ω 100–≥.—á–∞‚Ä¶</td><td>true</td><td>0.0</td><td>&quot;Tea&quot;</td><td>2.0</td><td>&quot;https://safebite-s3.s3.amazona‚Ä¶</td><td>56510</td><td>&quot;03zvGGbYBDpKSi1VJNbH&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ protein ‚îÜ fat  ‚îÜ title         ‚îÜ is_edible ‚îÜ ‚Ä¶ ‚îÜ calories ‚îÜ public_url    ‚îÜ id    ‚îÜ _id          ‚îÇ\n",
       "‚îÇ ---     ‚îÜ ---  ‚îÜ ---           ‚îÜ ---       ‚îÜ   ‚îÜ ---      ‚îÜ ---           ‚îÜ ---   ‚îÜ ---          ‚îÇ\n",
       "‚îÇ f64     ‚îÜ f64  ‚îÜ str           ‚îÜ bool      ‚îÜ   ‚îÜ f64      ‚îÜ str           ‚îÜ i64   ‚îÜ str          ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 0.0     ‚îÜ 0.0  ‚îÜ –ó–µ–ª—ë–Ω—ã–π       ‚îÜ true      ‚îÜ ‚Ä¶ ‚îÜ 2.0      ‚îÜ https://safeb ‚îÜ 69972 ‚îÜ 01Uz9Eh4tMKk ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ —á–∞–π_Bayce     ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ ite-s3.s3.ama ‚îÜ       ‚îÜ kUI8zmTr     ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ 95-11 400–≥—Ä   ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ zona‚Ä¶         ‚îÜ       ‚îÜ              ‚îÇ\n",
       "‚îÇ 1.0     ‚îÜ 2.5  ‚îÜ –ú–æ—Ä–æ–∂. –ë–æ–Ω    ‚îÜ true      ‚îÜ ‚Ä¶ ‚îÜ 125.0    ‚îÜ https://safeb ‚îÜ 69332 ‚îÜ 01YaRoAioWVJ ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ –ü–∞—Ä–∏ —Å        ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ ite-s3.s3.ama ‚îÜ       ‚îÜ aPOTy85E     ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ —Ñ—Ä—É–∫—Ç.—Å–æ–∫–æ–º   ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ zona‚Ä¶         ‚îÜ       ‚îÜ              ‚îÇ\n",
       "‚îÇ -1.0    ‚îÜ -1.0 ‚îÜ –®–æ–∫ –ø–ª–∏—Ç      ‚îÜ true      ‚îÜ ‚Ä¶ ‚îÜ -1.0     ‚îÜ https://safeb ‚îÜ 9041  ‚îÜ 02UfvwkJzBRy ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ –†–æ—Å—Å–∏—è —Ç–µ–º    ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ ite-s3.s3.ama ‚îÜ       ‚îÜ UHDFdq2v     ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ –º–∏–Ω–¥–∞–ª—å 82‚Ä¶   ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ zona‚Ä¶         ‚îÜ       ‚îÜ              ‚îÇ\n",
       "‚îÇ 27.5    ‚îÜ 25.0 ‚îÜ Delmark_–°/–ö_–û ‚îÜ true      ‚îÜ ‚Ä¶ ‚îÜ 350.0    ‚îÜ https://safeb ‚îÜ 43181 ‚îÜ 035LM4tsGLrK ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ —Ö–æ—Ç–Ω–∏—á—å—è      ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ ite-s3.s3.ama ‚îÜ       ‚îÜ LY9QpQ2m     ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ               ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ zona‚Ä¶         ‚îÜ       ‚îÜ              ‚îÇ\n",
       "‚îÇ 0.0     ‚îÜ 0.0  ‚îÜ –ì–†–ò–ù–§–ò–õ–î      ‚îÜ true      ‚îÜ ‚Ä¶ ‚îÜ 2.0      ‚îÜ https://safeb ‚îÜ 56510 ‚îÜ 03zvGGbYBDpK ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ –ì–æ–ª–¥–µ–Ω –¶–µ–π–ª–æ–Ω ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ ite-s3.s3.ama ‚îÜ       ‚îÜ Si1VJNbH     ‚îÇ\n",
       "‚îÇ         ‚îÜ      ‚îÜ 100–≥.—á–∞‚Ä¶      ‚îÜ           ‚îÜ   ‚îÜ          ‚îÜ zona‚Ä¶         ‚îÜ       ‚îÜ              ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pl.read_excel(DATA_DIR / \"smartdiet_dataset.xlsx\")\n",
    "print(f\"Loaded {len(df)} products from dataset\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image_path: str) -> np.ndarray | None:\n",
    "    \"\"\"Generate CLIP embedding for a single image.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGBA\")\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "        \n",
    "        # Normalize the embedding\n",
    "        embedding = image_features.cpu().numpy().flatten()\n",
    "        embedding = embedding / np.linalg.norm(embedding)\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_product_embedding(product_id: int, aggregation: str = \"mean\") -> np.ndarray | None:\n",
    "    \"\"\"Get aggregated embedding for all images of a product.\"\"\"\n",
    "    product_dir = IMAGES_DIR / str(product_id)\n",
    "    \n",
    "    if not product_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    image_files = list(product_dir.glob(\"*.jpg\")) + list(product_dir.glob(\"*.png\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        return None\n",
    "    \n",
    "    embeddings = []\n",
    "    for img_path in image_files:\n",
    "        emb = get_image_embedding(str(img_path))\n",
    "        if emb is not None:\n",
    "            embeddings.append(emb)\n",
    "    \n",
    "    if not embeddings:\n",
    "        return None\n",
    "    \n",
    "    # Aggregate embeddings (mean or first)\n",
    "    if aggregation == \"mean\":\n",
    "        agg_embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        agg_embedding = embeddings[0]\n",
    "    \n",
    "    # Normalize again after aggregation\n",
    "    agg_embedding = agg_embedding / np.linalg.norm(agg_embedding)\n",
    "    return agg_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 products...\n",
      "Processed 200 products...\n",
      "Processed 300 products...\n",
      "Processed 400 products...\n",
      "Processed 500 products...\n",
      "Processed 600 products...\n",
      "Processed 700 products...\n",
      "Processed 800 products...\n",
      "Processed 900 products...\n",
      "Processed 1000 products...\n",
      "Processed 1100 products...\n",
      "Processed 1200 products...\n",
      "Processed 1300 products...\n",
      "Processed 1400 products...\n",
      "Processed 1500 products...\n",
      "Processed 1600 products...\n",
      "Processed 1700 products...\n",
      "Processed 1800 products...\n",
      "Processed 1900 products...\n",
      "Processed 2000 products...\n",
      "Processed 2100 products...\n",
      "Processed 2200 products...\n",
      "Processed 2300 products...\n",
      "Processed 2400 products...\n",
      "Processed 2500 products...\n",
      "Processed 2600 products...\n",
      "Processed 2700 products...\n",
      "Processed 2800 products...\n",
      "Processed 2900 products...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedogeek/Documents/code/smartdiet/data/.venv/lib/python3.13/site-packages/PIL/JpegImagePlugin.py:873: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3000 products...\n",
      "Processed 3100 products...\n",
      "Processed 3200 products...\n",
      "Processed 3300 products...\n",
      "Processed 3400 products...\n",
      "Processed 3500 products...\n",
      "Processed 3600 products...\n",
      "Processed 3700 products...\n",
      "Processed 3800 products...\n",
      "Processed 3900 products...\n",
      "Processed 4000 products...\n",
      "\n",
      "Total products with embeddings: 4084\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all products with images\n",
    "embeddings_list = []\n",
    "metadata_list = []  # Store product info for each embedding\n",
    "\n",
    "for row in df.iter_rows(named=True):\n",
    "    product_id = row[\"id\"]\n",
    "    \n",
    "    embedding = get_product_embedding(product_id)\n",
    "    \n",
    "    if embedding is not None:\n",
    "        embeddings_list.append(embedding)\n",
    "        metadata_list.append({\n",
    "            \"id\": product_id,\n",
    "            \"_id\": row[\"_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"category\": row[\"category\"],\n",
    "            \"calories\": row[\"calories\"],\n",
    "            \"protein\": row[\"protein\"],\n",
    "            \"fat\": row[\"fat\"],\n",
    "            \"carbohydrates\": row[\"carbohydrates\"],\n",
    "        })\n",
    "        \n",
    "        if len(embeddings_list) % 100 == 0:\n",
    "            print(f\"Processed {len(embeddings_list)} products...\")\n",
    "\n",
    "print(f\"\\nTotal products with embeddings: {len(embeddings_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d0c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 512\n",
      "Embeddings shape: (4084, 512)\n",
      "FAISS index created with 4084 vectors\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index\n",
    "embeddings_array = np.array(embeddings_list).astype(\"float32\")\n",
    "dimension = embeddings_array.shape[1]\n",
    "\n",
    "print(f\"Embedding dimension: {dimension}\")\n",
    "print(f\"Embeddings shape: {embeddings_array.shape}\")\n",
    "\n",
    "# Create index - using IndexFlatIP for cosine similarity (since vectors are normalized)\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings_array)\n",
    "\n",
    "print(f\"FAISS index created with {index.ntotal} vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3dfe847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index to: /home/nedogeek/Documents/code/smartdiet/data/data/index/products.index\n",
      "Saved metadata to: /home/nedogeek/Documents/code/smartdiet/data/data/index/products_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save FAISS index and metadata\n",
    "faiss.write_index(index, str(INDEX_DIR / \"products.index\"))\n",
    "\n",
    "with open(INDEX_DIR / \"products_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved index to: {INDEX_DIR / 'products.index'}\")\n",
    "print(f\"Saved metadata to: {INDEX_DIR / 'products_metadata.json'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "122ba030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_products(query_image_path: str, top_k: int = 5) -> list[dict]:\n",
    "    \"\"\"Search for similar products given an image path.\"\"\"\n",
    "    # Get embedding for query image\n",
    "    query_embedding = get_image_embedding(query_image_path)\n",
    "    \n",
    "    if query_embedding is None:\n",
    "        return []\n",
    "    \n",
    "    query_embedding = query_embedding.reshape(1, -1).astype(\"float32\")\n",
    "    \n",
    "    # Search in FAISS index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "        result = metadata_list[idx].copy()\n",
    "        result[\"similarity_score\"] = float(dist)\n",
    "        result[\"rank\"] = i + 1\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def search_by_text(query_text: str, top_k: int = 5) -> list[dict]:\n",
    "    \"\"\"Search for products using text query (CLIP text encoder).\"\"\"\n",
    "    inputs = processor(text=[query_text], return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**inputs)\n",
    "    \n",
    "    # Normalize\n",
    "    query_embedding = text_features.cpu().numpy().flatten()\n",
    "    query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "    query_embedding = query_embedding.reshape(1, -1).astype(\"float32\")\n",
    "    \n",
    "    # Search\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "        result = metadata_list[idx].copy()\n",
    "        result[\"similarity_score\"] = float(dist)\n",
    "        result[\"rank\"] = i + 1\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3691cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Text search: 'chocolate bar'\n",
      "\n",
      "#1 [0.349] –®–æ–∫.–±–∞—Ç–æ–Ω—á–∏–∫ –ê–ª—ë–Ω–∫–∞ —Å –≤–∞—Ä —Å–≥—É—â 48–≥ (Snack)\n",
      "#2 [0.346] –®–æ–∫. KinChocolate 100–≥ (Chocolate)\n",
      "#3 [0.345] –®–æ–∫–æ–ª.–ø–ª–∏—Ç–∫–∞ Geisha –º–æ–ª.—à–æ–∫.—Å –Ω–∞—á–∏–Ω. (Confectionery)\n",
      "#4 [0.345] –®–æ–∫–æ–ª.–±–∞—Ç.Karl Fazer —Ö—Ä—É—Å.—à–æ–∫–æ–ª.—Ç—Ä—é—Ñ.37–≥ (Snack)\n",
      "#5 [0.343] –®–æ–∫–æ–ª–∞–¥.–∫–æ–Ω—Ñ.Karl Fazer —Ç–µ–º–Ω.—à–æ–∫.70% (Chocolate)\n"
     ]
    }
   ],
   "source": [
    "# Demo: Search by text\n",
    "print(\"üîç Text search: 'chocolate bar'\\n\")\n",
    "results = search_by_text(\"chocolate bar\", top_k=5)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"#{r['rank']} [{r['similarity_score']:.3f}] {r['title']} ({r['category']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e69331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Image search: using image from product '–ó–µ–ª—ë–Ω—ã–π —á–∞–π_Bayce 95-11 400–≥—Ä'\n",
      "\n",
      "#1 [0.913] –ó–µ–ª—ë–Ω—ã–π —á–∞–π_Bayce 95-11 400–≥—Ä (Beverage)\n",
      "#2 [0.889] –ß–∞–π Bayce –∑–µ–ª—ë–Ω—ã–π ‚Ññ95 80–≥—Ä (Beverage)\n",
      "#3 [0.877] –ó–µ–ª—ë–Ω—ã–π —á–∞–π_Bayce 110-11 400–≥—Ä (Beverages)\n",
      "#4 [0.856] –ß–∞–π Bayce –ó–µ–ª—ë–Ω—ã–π ‚Ññ66 –º/—É 400–≥ (Beverage)\n",
      "#5 [0.805] –ß–∞–π Bayce –∑–µ–ª—ë–Ω—ã–π 110-11 (Beverage)\n"
     ]
    }
   ],
   "source": [
    "# Demo: Search by image (using first product's image as query)\n",
    "sample_product_id = metadata_list[0][\"id\"]\n",
    "sample_image_dir = IMAGES_DIR / str(sample_product_id)\n",
    "sample_images = list(sample_image_dir.glob(\"*.jpg\"))\n",
    "\n",
    "if sample_images:\n",
    "    print(f\"üñºÔ∏è Image search: using image from product '{metadata_list[0]['title']}'\\n\")\n",
    "    results = search_similar_products(str(sample_images[0]), top_k=5)\n",
    "    \n",
    "    for r in results:\n",
    "        print(f\"#{r['rank']} [{r['similarity_score']:.3f}] {r['title']} ({r['category']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fbe95",
   "metadata": {},
   "source": [
    "## Loading the Index for Production Use\n",
    "\n",
    "To load the saved index in another script or application:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c850752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index files saved! Ready for production use.\n"
     ]
    }
   ],
   "source": [
    "# Example: How to load the saved index in another script\n",
    "\"\"\"\n",
    "import faiss\n",
    "import json\n",
    "\n",
    "# Load index\n",
    "index = faiss.read_index(\"data/index/products.index\")\n",
    "\n",
    "# Load metadata\n",
    "with open(\"data/index/products_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Now you can use:\n",
    "# distances, indices = index.search(query_embedding, top_k)\n",
    "# product_info = metadata[indices[0][0]]\n",
    "\"\"\"\n",
    "\n",
    "print(\"Index files saved! Ready for production use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass any image path to find similar products\n",
    "results = search_similar_products(\"/home/nedogeek/Documents/code/smartdiet/data/data/images/830/000003.jpg\", top_k=5)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r['title']} - Score: {r['similarity_score']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
